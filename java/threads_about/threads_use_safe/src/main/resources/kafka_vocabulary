Borker负责接收和处理客户端发送过来的请求,以及对消息的持久化.
虽然多个borker可以在同一台机器上,但更常见的便是将不同的broker分散在不同的机器上,这样即便挂了集群中某一台,
其他的机器上的broker也能继续提供服务.

-------

副本机制: 领导者副本/追随者副本. 前者对外提供服务,就是与客户端进行交互;而后者只是被动的追随领导者副本,追随副本不对外提供服务.

能否给数据分割多份保存在不同的borker上? 分区(Partitioning).
每个topic划分为多个分区,每个分区是一组有序的消息队列.生产者生产的每条消息只会被发送到一个分区中,
也就是说如果一个双分区的主题发送一条消息,这条消息要么在分区0中,要么在分区1中.

副本与分区?
副本是在分区这个层级定义的,每个分区下可以配置若干副本,其中只有1个领导者副本和N-1追随者副本.
第一层: 每个topic可以配置M个分区,而每个分区就又可以配置N个副本.
第二层: 每个分区的N个副本中只能有一个充当领导者角色,对外提供服务,其他N-1副本是追随者副本,只是提供数据冗余。
第三次: 分区中包含若干消息,每条消息的位移从0开始，依次递增.
最后: 客户端程序只能与分区的领导者副本进行交互.

Kafka Broker是如何持久化数据的?
使用消息日志(log)来保存数据,一个日志就是磁盘上一个只能追加写(Append-only)消息的物理文件.
因为只能追加,所以避免了缓慢的缓存I/O操作,使用的是性能较好的顺序I/O写操作.
Log Segment机制，一个日志又进一步细分为多个日志段,消息被追加写到当前最新的日志中,当写满一个日志段后,kafka会自动切换
分出一个新的日志段,并将老的日志段封存起来.Kafka会后台检查老的日志是否能被删除.



------------------------------
消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
生产者：Producer。向主题发布新消息的应用程序。
消费者：Consumer。从主题订阅新消息的应用程序。
消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

-------------------
分区策略:
    轮询策略: Kafka Java生产者API默认提供的分区策略.
    随机策略: 老版本还有,新的版本没有了.
    Key-ordering策略: Kafka容许每条消息自定义key. 可以保证同一个key的所有消息都进入到相同的分区里面,由于每个分区下的消息处理顺序都是有序的.

-----------
TCP能能够被用于多路复用连接场景前提,

--------------
位移的主题Key中应该保存3部分内容, <Group ID , Topic Name , 分区号 >

--------
Rebalance 有关参数,
1: 如果未能及时发送心跳,导致consumer被踢出Group. session.timeout.ms和heartbeat.interval.ms有关.
2: Consumer 消费时间过长导致的.
GC参数

--------
提交位移(Committing Offsets). 因为Consumer能够消费多个分区数据,所以位移的提交实际上是在分区粒度上进行的,
即Consumer需要为分配给它的每个分区提交各自的位移数据.
位移提交的语义保障是由你来负责的,Kafka只会接受你提交的位移.

-----------


